{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bc8aaa0-a131-4f9a-a14e-18bfb9f3e7a1",
   "metadata": {},
   "source": [
    "**plot timeseries of Surface Temperature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a3ba823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:36:13) [GCC 12.3.0]\n",
      "pjr3.py xxx complete\n"
     ]
    }
   ],
   "source": [
    "### script rewrite not completed because Haruki already built a nice plot update\n",
    "1./0.\n",
    "import sys\n",
    "print(sys.version)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "xr.set_options(keep_attrs=True)\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# load some useful functions written or acquired by phil rasch\n",
    "%run -i ~/Python/pjr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "981f8ea0-f91a-45b2-8509-3c9f74290813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a file that will hold all the filenames used by the program\n",
    "flname = '/tmp/flname'\n",
    "file = open(flname, 'w')\n",
    "file.write('list of files used by gavg_xxx\\n')\n",
    "file.close()\n",
    "file = open(flname, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "176b146d-e168-440c-bb62-fe7689d3d550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fnprefix='GAVG_tsers_E3SM_and_CESM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16f2e1fd-4d68-47bb-a961-e16c27adf2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "center_time returning DS 2015-01-16 12:00:00 2015-02-15 00:00:00 2064-11-16 00:00:00 2064-12-16 12:00:00\n",
      "V3 <xarray.DataArray (year: 50)> Size: 400B\n",
      "array([288.18273941, 288.08608421, 287.994847  , 288.02474933,\n",
      "       288.1260194 , 288.01559749, 287.94675926, 287.90734245,\n",
      "       287.96855043, 288.149259  , 287.9960639 , 287.98605561,\n",
      "       288.1332144 , 288.17097463, 288.37969401, 288.3350707 ,\n",
      "       288.1776492 , 287.88897798, 287.95721356, 288.14714158,\n",
      "       288.09937627, 288.19896061, 288.26692431, 288.19334773,\n",
      "       288.223602  , 288.1906918 , 288.36848188, 288.37198529,\n",
      "       288.35189473, 288.42936557, 288.50151251, 288.57720776,\n",
      "       288.62802858, 288.56762208, 288.67789136, 288.80132033,\n",
      "       288.83914874, 288.87140325, 288.82053859, 288.90935046,\n",
      "       288.9603476 , 288.97346704, 288.94747296, 289.17989514,\n",
      "       289.09367947, 289.02908114, 289.15185112, 289.3188904 ,\n",
      "       289.45615691, 289.42750422])\n",
      "Coordinates:\n",
      "  * year     (year) int64 400B 2015 2016 2017 2018 2019 ... 2061 2062 2063 2064\n",
      "Attributes:\n",
      "    cell_methods:   time: mean\n",
      "    long_name:      Surface temperature (radiative)\n",
      "    standard_name:  surface_temperature\n",
      "    units:          K\n",
      "center_time returning DS 2015-01-16 12:00:00 2015-02-15 00:00:00 2084-11-16 00:00:00 2084-12-16 12:00:00\n",
      "V2 <xarray.DataArray (year: 70)> Size: 560B\n",
      "array([288.27742566, 288.20331598, 288.26361667, 288.33747263,\n",
      "       288.48670414, 288.76120195, 288.72587991, 288.69345147,\n",
      "       288.83893352, 288.96575163, 288.76417255, 288.76775369,\n",
      "       288.80571184, 288.827881  , 288.82363733, 288.85310672,\n",
      "       289.03676886, 288.94079583, 289.01536359, 288.98833206,\n",
      "       289.02433259, 289.11047685, 289.35734695, 289.30839426,\n",
      "       289.41210096, 289.51410744, 289.55918661, 289.37967514,\n",
      "       289.45631926, 289.59905974, 289.61159631, 289.64147019,\n",
      "       289.8056868 , 289.87679052, 289.78501645, 289.83149233,\n",
      "       289.88003221, 289.98720278, 289.96288311, 290.11088561,\n",
      "       290.06756293, 289.9713199 , 290.25661175, 290.2864267 ,\n",
      "       290.22929813, 290.30982858, 290.08976932, 290.18340977,\n",
      "       290.19292602, 290.45210907, 290.43152749, 290.33541297,\n",
      "       290.42691303, 290.29436812, 290.5206087 , 290.56419023,\n",
      "       290.65875249, 290.57569221, 290.49162218, 290.60793853,\n",
      "       290.64338319, 290.74503906, 290.87458276, 290.92403086,\n",
      "       290.73330047, 290.90539525, 290.91296417, 290.98708925,\n",
      "       290.98600602, 291.03949013])\n",
      "Coordinates:\n",
      "  * year     (year) int64 560B 2015 2016 2017 2018 2019 ... 2081 2082 2083 2084\n",
      "Attributes:\n",
      "    cell_methods:   time: mean\n",
      "    long_name:      Surface temperature (radiative)\n",
      "    standard_name:  surface_temperature\n",
      "    units:          K\n",
      "center_time returning DS 2015-01-16 12:00:00 2015-02-15 00:00:00 2065-11-16 00:00:00 2065-12-16 12:00:00\n",
      "V1 <xarray.DataArray (year: 51)> Size: 408B\n",
      "array([288.19604945, 288.01329582, 287.84295284, 287.84589292,\n",
      "       287.92893524, 288.01112447, 287.96197384, 287.91803679,\n",
      "       287.96859454, 288.10201371, 287.95423666, 287.90930751,\n",
      "       287.91276795, 288.06155794, 288.1640117 , 288.35455707,\n",
      "       288.18518694, 288.24113264, 288.22506188, 288.18703882,\n",
      "       288.14031025, 288.27149268, 288.31845258, 288.29788809,\n",
      "       288.40547889, 288.44711761, 288.38440189, 288.4370963 ,\n",
      "       288.47128684, 288.59624119, 288.57160647, 288.66541494,\n",
      "       288.70882165, 288.7481313 , 288.73337879, 288.74149612,\n",
      "       288.73869989, 288.87159195, 288.93210221, 288.96080057,\n",
      "       289.08466789, 289.29501029, 289.41295181, 289.33268317,\n",
      "       289.50062413, 289.51711086, 289.51659155, 289.60145521,\n",
      "       289.61675834, 289.6631208 , 289.64097323])\n",
      "Coordinates:\n",
      "  * year     (year) int64 408B 2015 2016 2017 2018 2019 ... 2062 2063 2064 2065\n",
      "Attributes:\n",
      "    cell_methods:   time: mean\n",
      "    long_name:      Surface temperature (radiative)\n",
      "    standard_name:  surface_temperature\n",
      "    units:          K\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "var = 'TS'\n",
    "\n",
    "experiment = \"20230724.v2.LR.WCYCLSSP245.MCB-SSLT-EM.R1-3.test01\"\n",
    "s3_path = f's3://mcb-zarr/E3SMv2/{experiment}/atm/proc/tseries/month_1/{experiment}.eam.h0.{var}.zarr'\n",
    "V3 = make_GA_ts2(var, s3_path )\n",
    "print('V3',V3)\n",
    "\n",
    "experiment = \"20221014.v2.LR.WCYCLSSP245.E2_CNTL_01\"\n",
    "s3_path = f's3://mcb-zarr/E3SMv2/{experiment}/atm/proc/tseries/month_1/{experiment}.eam.h0.{var}.zarr'\n",
    "#DS1 = s3load_zarr(s3_path)\n",
    "#print('xxx',DS1)\n",
    "#DS1 = xr.open_mfdataset(ind1)\n",
    "#DS1 = center_time(DS1)\n",
    "V2 = make_GA_ts2(var, s3_path )\n",
    "print('V2',V2)\n",
    "\n",
    "experiment = '20221128.v2.LR.WCYCLSSP245.E2_CNTL_01.R1-3_CDNC2000'\n",
    "s3_path = f's3://mcb-zarr/E3SMv2/{experiment}/atm/proc/tseries/month_1/{experiment}.eam.h0.{var}.zarr'\n",
    "V1 = make_GA_ts2(var, s3_path )\n",
    "print('V1',V1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3823f397-bca0-4aa2-86da-6cdd24aa1bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yyy s3://mcb-zarr/E3SMv2/20221128.v2.LR.WCYCLSSP245.E2_CNTL_01.R1-3_CDNC2000/atm/proc/tseries/month_1/20221128.v2.LR.WCYCLSSP245.E2_CNTL_01.R1-3_CDNC2000.eam.h0.TS.zarr\n",
      "s3_path s3://mcb-zarr/CESM2/b.e21.BSSP245smbb_MCB600cm_R1R2R3.f09_g17.LE2-1011.001/atm/proc/tseries/month_1/b.e21.BSSP245smbb_MCB600cm_R1R2R3.f09_g17.LE2-1011.001.cam.h0.TS.2015-2064.zarr\n",
      "s3_path s3://mcb-zarr/CESM2/b.e21.BSSP245smbb.f09_g17.001/atm/proc/tseries/month_1/b.e21.BSSP245smbb.f09_g17.001.cam.h0.TS.zarr\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: '<fsspec.mapping.FSMap object at 0x7febcebdcdd0>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchKey\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/s3fs/core.py:113\u001b[0m, in \u001b[0;36m_error_wrapper\u001b[0;34m(func, args, kwargs, retries)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m S3_RETRYABLE_ERRORS \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/aiobotocore/client.py:411\u001b[0m, in \u001b[0;36mAioBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    410\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 411\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mNoSuchKey\u001b[0m: An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/fsspec/mapping.py:155\u001b[0m, in \u001b[0;36mFSMap.__getitem__\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing_exceptions:\n",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/fsspec/asyn.py:118\u001b[0m, in \u001b[0;36msync_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m obj \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/fsspec/asyn.py:103\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/fsspec/asyn.py:56\u001b[0m, in \u001b[0;36m_runner\u001b[0;34m(event, coro, result, timeout)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/fsspec/asyn.py:461\u001b[0m, in \u001b[0;36mAsyncFileSystem._cat\u001b[0;34m(self, path, recursive, on_error, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ex:\n\u001b[0;32m--> 461\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28mlen\u001b[39m(paths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m paths[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strip_protocol(path)\n\u001b[1;32m    466\u001b[0m ):\n",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/fsspec/asyn.py:245\u001b[0m, in \u001b[0;36m_run_coros_in_chunks.<locals>._run_coro\u001b[0;34m(coro, i)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mwait_for(coro, timeout\u001b[38;5;241m=\u001b[39mtimeout), i\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/asyncio/tasks.py:452\u001b[0m, in \u001b[0;36mwait_for\u001b[0;34m(fut, timeout)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/s3fs/core.py:1128\u001b[0m, in \u001b[0;36mS3FileSystem._cat_file\u001b[0;34m(self, path, version_id, start, end)\u001b[0m\n\u001b[1;32m   1126\u001b[0m         resp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBody\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _error_wrapper(_call_and_read, retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries)\n",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/s3fs/core.py:145\u001b[0m, in \u001b[0;36m_error_wrapper\u001b[0;34m(func, args, kwargs, retries)\u001b[0m\n\u001b[1;32m    144\u001b[0m err \u001b[38;5;241m=\u001b[39m translate_boto_error(err)\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/s3fs/core.py:113\u001b[0m, in \u001b[0;36m_error_wrapper\u001b[0;34m(func, args, kwargs, retries)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m S3_RETRYABLE_ERRORS \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/s3fs/core.py:1115\u001b[0m, in \u001b[0;36mS3FileSystem._cat_file.<locals>._call_and_read\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_and_read\u001b[39m():\n\u001b[0;32m-> 1115\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_s3(\n\u001b[1;32m   1116\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_object\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1117\u001b[0m         Bucket\u001b[38;5;241m=\u001b[39mbucket,\n\u001b[1;32m   1118\u001b[0m         Key\u001b[38;5;241m=\u001b[39mkey,\n\u001b[1;32m   1119\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mversion_id_kw(version_id \u001b[38;5;129;01mor\u001b[39;00m vers),\n\u001b[1;32m   1120\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhead,\n\u001b[1;32m   1121\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreq_kw,\n\u001b[1;32m   1122\u001b[0m     )\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/s3fs/core.py:365\u001b[0m, in \u001b[0;36mS3FileSystem._call_s3\u001b[0;34m(self, method, *akwarglist, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m additional_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_s3_method_kwargs(method, \u001b[38;5;241m*\u001b[39makwarglist, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _error_wrapper(\n\u001b[1;32m    366\u001b[0m     method, kwargs\u001b[38;5;241m=\u001b[39madditional_kwargs, retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries\n\u001b[1;32m    367\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/s3fs/core.py:145\u001b[0m, in \u001b[0;36m_error_wrapper\u001b[0;34m(func, args, kwargs, retries)\u001b[0m\n\u001b[1;32m    144\u001b[0m err \u001b[38;5;241m=\u001b[39m translate_boto_error(err)\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: The specified key does not exist.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/zarr/storage.py:1446\u001b[0m, in \u001b[0;36mFSStore.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/fsspec/mapping.py:159\u001b[0m, in \u001b[0;36mFSMap.__getitem__\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyError\u001b[0m: '.zmetadata'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/xarray/backends/zarr.py:475\u001b[0m, in \u001b[0;36mZarrStore.open_group\u001b[0;34m(cls, store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, append_dim, write_region, safe_chunks, stacklevel, zarr_version, write_empty)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m     zarr_group \u001b[38;5;241m=\u001b[39m \u001b[43mzarr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_consolidated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/zarr/convenience.py:1360\u001b[0m, in \u001b[0;36mopen_consolidated\u001b[0;34m(store, metadata_key, mode, **kwargs)\u001b[0m\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;66;03m# setup metadata store\u001b[39;00m\n\u001b[0;32m-> 1360\u001b[0m meta_store \u001b[38;5;241m=\u001b[39m \u001b[43mConsolidatedStoreClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[38;5;66;03m# pass through\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/zarr/storage.py:3046\u001b[0m, in \u001b[0;36mConsolidatedMetadataStore.__init__\u001b[0;34m(self, store, metadata_key)\u001b[0m\n\u001b[1;32m   3045\u001b[0m \u001b[38;5;66;03m# retrieve consolidated metadata\u001b[39;00m\n\u001b[0;32m-> 3046\u001b[0m meta \u001b[38;5;241m=\u001b[39m json_loads(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetadata_key\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m   3048\u001b[0m \u001b[38;5;66;03m# check format of consolidated metadata\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/zarr/storage.py:1448\u001b[0m, in \u001b[0;36mFSStore.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: '.zmetadata'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mGroupNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/xarray/backends/zarr.py:478\u001b[0m, in \u001b[0;36mZarrStore.open_group\u001b[0;34m(cls, store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, append_dim, write_region, safe_chunks, stacklevel, zarr_version, write_empty)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 478\u001b[0m     zarr_group \u001b[38;5;241m=\u001b[39m \u001b[43mzarr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to open Zarr store with consolidated metadata, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut successfully read with non-consolidated metadata. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    492\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    493\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/zarr/hierarchy.py:1578\u001b[0m, in \u001b[0;36mopen_group\u001b[0;34m(store, mode, cache_attrs, synchronizer, path, chunk_store, storage_options, zarr_version, meta_array)\u001b[0m\n\u001b[1;32m   1577\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m ContainsArrayError(path)\n\u001b[0;32m-> 1578\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m GroupNotFoundError(path)\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mGroupNotFoundError\u001b[0m: group not found at path ''",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m s3_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms3://mcb-zarr/CESM2/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/atm/proc/tseries/month_1/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.cam.h0.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.zarr\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms3_path\u001b[39m\u001b[38;5;124m'\u001b[39m,s3_path)\n\u001b[0;32m---> 31\u001b[0m DS5 \u001b[38;5;241m=\u001b[39m \u001b[43ms3load_zarr\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms3_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDS5\u001b[39m\u001b[38;5;124m'\u001b[39m,DS5)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m0.\u001b[39m\n",
      "File \u001b[0;32m~/Python/pjr3.py:42\u001b[0m, in \u001b[0;36ms3load_zarr\u001b[0;34m(s3path)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21ms3load_zarr\u001b[39m(s3path):\n\u001b[1;32m     41\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" return an xarray DataSet given an s3path \"\"\"\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfsspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_mapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms3path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzarr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/xarray/backends/api.py:571\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    560\u001b[0m     decode_cf,\n\u001b[1;32m    561\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    568\u001b[0m )\n\u001b[1;32m    570\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 571\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    578\u001b[0m     backend_ds,\n\u001b[1;32m    579\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    590\u001b[0m )\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/xarray/backends/zarr.py:1170\u001b[0m, in \u001b[0;36mZarrBackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, synchronizer, consolidated, chunk_store, storage_options, stacklevel, zarr_version)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataset\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]  # allow LSP violation, not supporting **kwargs\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1151\u001b[0m     filename_or_obj: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m os\u001b[38;5;241m.\u001b[39mPathLike[Any] \u001b[38;5;241m|\u001b[39m BufferedIOBase \u001b[38;5;241m|\u001b[39m AbstractDataStore,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1167\u001b[0m     zarr_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1168\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dataset:\n\u001b[1;32m   1169\u001b[0m     filename_or_obj \u001b[38;5;241m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[0;32m-> 1170\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[43mZarrStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynchronizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsolidated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsolidate_on_close\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstacklevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstacklevel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzarr_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzarr_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1183\u001b[0m     store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n",
      "File \u001b[0;32m~/.conda/envs/pjrpy3/lib/python3.11/site-packages/xarray/backends/zarr.py:495\u001b[0m, in \u001b[0;36mZarrStore.open_group\u001b[0;34m(cls, store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, append_dim, write_region, safe_chunks, stacklevel, zarr_version, write_empty)\u001b[0m\n\u001b[1;32m    479\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    480\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to open Zarr store with consolidated metadata, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    481\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut successfully read with non-consolidated metadata. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    492\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    493\u001b[0m             )\n\u001b[1;32m    494\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m zarr\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mGroupNotFoundError:\n\u001b[0;32m--> 495\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m consolidated:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;66;03m# TODO: an option to pass the metadata_key keyword\u001b[39;00m\n\u001b[1;32m    498\u001b[0m     zarr_group \u001b[38;5;241m=\u001b[39m zarr\u001b[38;5;241m.\u001b[39mopen_consolidated(store, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopen_kwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: '<fsspec.mapping.FSMap object at 0x7febcebdcdd0>'"
     ]
    }
   ],
   "source": [
    "\n",
    "tit1 = \"E3SM CDNC2000, NEP,SEP,SEA\"\n",
    "case1 = '20221128.v2.LR.WCYCLSSP245.E2_CNTL_01.R1-3_CDNC2000'\n",
    "var = 'TS'\n",
    "s3_path = f's3://mcb-zarr/E3SMv2/{case1}/atm/proc/tseries/month_1/{case1}.eam.h0.{var}.zarr'\n",
    "print('yyy',s3_path)\n",
    "DS1 = s3load_zarr(s3_path)\n",
    "#print('DS1',DS1)\n",
    "\n",
    "tit2 = \"E3SM Control\"\n",
    "experiment = \"20221014.v2.LR.WCYCLSSP245.E2_CNTL_01\"\n",
    "s3_path = f's3://mcb-zarr/E3SMv2/{experiment}/atm/proc/tseries/month_1/{experiment}.eam.h0.{var}.zarr'\n",
    "DS2 = s3load_zarr(s3_path)\n",
    "#print('DS2',DS2)\n",
    "\n",
    "tit3 = \"E3SM 49Tg/yr, NEP,SEP,SEA\"\n",
    "experiment = \"20230724.v2.LR.WCYCLSSP245.MCB-SSLT-EM.R1-3.test01\"\n",
    "s3_path = f's3://mcb-zarr/E3SMv2/{experiment}/atm/proc/tseries/month_1/{experiment}.eam.h0.{var}.zarr'\n",
    "DS3 = s3load_zarr(s3_path)\n",
    "#print('DS3',DS3)\n",
    "\n",
    "tit4 = \"CESM CDNC600, NEP,SEP,SEA\"\n",
    "experiment = \"b.e21.BSSP245smbb_MCB600cm_R1R2R3.f09_g17.LE2-1011.001\"\n",
    "s3_path = f's3://mcb-zarr/CESM2/{experiment}/atm/proc/tseries/month_1/{experiment}.cam.h0.{var}.2015-2064.zarr'\n",
    "print('s3_path',s3_path)\n",
    "DS4 = s3load_zarr(s3_path)\n",
    "#print('DS4',DS4)\n",
    "\n",
    "experiment = \"b.e21.BSSP245smbb.f09_g17.001\"\n",
    "s3_path = f's3://mcb-zarr/CESM2/{experiment}/atm/proc/tseries/month_1/{experiment}.cam.h0.{var}.zarr'\n",
    "print('s3_path',s3_path)\n",
    "DS5 = s3load_zarr(s3_path)\n",
    "print('DS5',DS5)\n",
    "1./0.\n",
    "\n",
    "ext5 = \".cam.h0\"\n",
    "ext5f = \".201501-206412.nc\"\n",
    "tit5 = \"CESM Control(e1)\"\n",
    "string5 = \"{dir:s}/{case:s}{ext:s}.{var:s}\"+ext5f\n",
    "\n",
    "dir6 = \"/e3sm_prod/phil/timeseries/cesm2-mcb-reshaped/CESM2_SSP245/ens002\"\n",
    "case6 = \"b.e21.BSSP245smbb.f09_g17.002\"\n",
    "ext6 = \".cam.h0\"\n",
    "ext6f = \".201501-206412.nc\"\n",
    "tit6 = \"CESM Control(e2)\"\n",
    "string6 = \"{dir:s}/{case:s}{ext:s}.{var:s}\"+ext6f\n",
    "\n",
    "dir7 = \"/e3sm_prod/phil/timeseries/cesm2-mcb-reshaped/CESM2_SSP245/ens003\"\n",
    "case7 = \"b.e21.BSSP245smbb.f09_g17.003\"\n",
    "ext7 = \".cam.h0\"\n",
    "ext7f = \".201501-206412.nc\"\n",
    "tit7 = \"CESM Control(e3)\"\n",
    "string7 = \"{dir:s}/{case:s}{ext:s}.{var:s}\"+ext7f\n",
    "\n",
    "dir8 = \"/e3sm_prod/phil/timeseries/cesm2-mcb-reshaped\"\n",
    "case8 = \"b.e21.BSSP245smbb_MCBss7TgYr_R1R2R3.f09_g17.LE2-1011.001\"\n",
    "ext8 = \".cam.h0.2015-2065\"\n",
    "ext8f = \".nc\"\n",
    "tit8 = \"CESM SSE 7 Tg/yr\"\n",
    "string8 = \"{dir:s}/{case:s}/{case:s}{ext:s}.{var:s}\"+ext8f\n",
    "\n",
    "filespec=string8.format(dir=dir8,case=case8,ext=ext8,var='TS')\n",
    "print(filespec)\n",
    "file.write(filespec+'\\n')\n",
    "ind = xr.open_mfdataset(filespec)\n",
    "\n",
    "Varlist = np.array(['RESTOM','FLNT','FSNT','TS','TMQ','PRECT','AEROD_v','CLDLOW','CLDTOT','LWCF','SWCF','TGCLDIWP','TGCLDLWP',\n",
    "                    'SHFLX','LHFLX','PBLH','PCONVT','PRECC','PRECS'])\n",
    "Varlist = np.array(['FLNT'])\n",
    "Varlist = np.array(['TS'])\n",
    "\n",
    "for Varname in Varlist:\n",
    "    print()\n",
    "    print('-------------------------------'+Varname)\n",
    "    \n",
    "    V8AY = make_GA_tser(Varname, string8, dir8, case8, ext8)\n",
    "    V8AY.coords['year'] = V8AY.coords['year'] - V8AY.coords['year'][0]\n",
    "    \n",
    "    V1AY = make_GA_tser(Varname, string1, dir1, case1, ext1)\n",
    "    #time = V1AY.coords['time']\n",
    "    V1AY.coords['year'] = V1AY.coords['year'] - V1AY.coords['year'][0]\n",
    "    V1AY\n",
    "    print('time',V1AY.coords['year'].values)\n",
    "    #V1AY.plot()\n",
    "    \n",
    "    V2AY = make_GA_tser(Varname, string2, dir2, case2, ext2)\n",
    "    V2AY.coords['year'] = V2AY.coords['year'] - V2AY.coords['year'][0]\n",
    "    print('time2',V2AY.coords['year'].values)\n",
    "    #V2AY.plot()\n",
    "\n",
    "    if True:\n",
    "        V3AY = make_GA_tser(Varname, string3, dir3, case3, ext3)\n",
    "        V3AY.coords['year'] = V3AY.coords['year'] - V3AY.coords['year'][0]\n",
    "        print('time3',V3AY.coords['year'].values)\n",
    "        \n",
    "    V4AY = make_GA_tser(Varname, string4, dir4, case4, ext4)\n",
    "    #time = V1AY.coords['time']\n",
    "    V4AY.coords['year'] = V4AY.coords['year'] - V4AY.coords['year'][0]\n",
    "    #print('time',V4AY.coords['year'].values)\n",
    "\n",
    "    V5AY = make_GA_tser(Varname, string5, dir5, case5, ext5)\n",
    "    V5AY.coords['year'] = V5AY.coords['year'] - V5AY.coords['year'][0]\n",
    "    \n",
    "    V6AY = make_GA_tser(Varname, string6, dir6, case6, ext6)\n",
    "    V6AY.coords['year'] = V6AY.coords['year'] - V6AY.coords['year'][0]\n",
    "    \n",
    "    V7AY = make_GA_tser(Varname, string7, dir7, case7, ext7)\n",
    "    V7AY.coords['year'] = V7AY.coords['year'] - V7AY.coords['year'][0]\n",
    "    \n",
    "\n",
    "    #V2AY.plot()\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1,\n",
    "                             #gridspec_kw={'width_ratios': [1]},\n",
    "                             #subplot_kw={'projection': plotproj},\n",
    "                             figsize=(6,4.1),\n",
    "                            )\n",
    "    fig.set_dpi(300.0)\n",
    "    \n",
    "    # two color tables (one for cesm, one for e3sm. Stay away from the smallest indices for icolors as it will be whitish)\n",
    "    ecolors = plt.cm.viridis(np.linspace(0, 1, 8))\n",
    "    ccolors = plt.cm.inferno_r(np.linspace(0, 1, 8))\n",
    "    ecolors = plt.cm.Purples(np.linspace(0, 1, 8))\n",
    "    ccolors = plt.cm.Oranges(np.linspace(0, 1, 8))\n",
    "    \n",
    "    # pert and control linestyes\n",
    "    pstyle = 'dotted'\n",
    "    cstyle = 'solid'\n",
    "    \n",
    "    V1AY = V1AY - V1AY[0]\n",
    "    V2AY = V2AY - V2AY[0]\n",
    "    V3AY = V3AY - V3AY[0]\n",
    "    V4AY = V4AY - V4AY[0]\n",
    "    V5AY = V5AY - V5AY[0]\n",
    "    V6AY = V6AY - V6AY[0]\n",
    "\n",
    "    V7AY = V7AY - V7AY[0]\n",
    "    V8AY = V8AY - V8AY[0]\n",
    "\n",
    "\n",
    "    #axes.text(0.5,1.01,\"ax title\")\n",
    "    V1AY.plot.line(ax=axes,label=tit1,color=ecolors[1,:],linestyle=pstyle)\n",
    "    V2AY.plot.line(ax=axes,label=tit2,color=ecolors[2,:],linestyle=cstyle)\n",
    "    V3AY.plot.line(ax=axes,label=tit3,color=ecolors[3,:],linestyle=pstyle)\n",
    "    V4AY.plot.line(ax=axes,label=tit4,color=ccolors[2,:],linestyle=pstyle)\n",
    "    V5AY.plot.line(ax=axes,label=tit5,color=ccolors[3,:],linestyle=cstyle)\n",
    "    V6AY.plot.line(ax=axes,label=tit6,color=ccolors[4,:],linestyle=cstyle)\n",
    "    V7AY.plot.line(ax=axes,label=tit7,color=ccolors[5,:],linestyle=cstyle)\n",
    "    V8AY.plot.line(ax=axes,label=tit8,color=ccolors[6,:],linestyle=pstyle)\n",
    "\n",
    "\n",
    "    Vmin = np.minimum(np.minimum(V5AY,V6AY),V7AY)\n",
    "    Vmax = np.maximum(np.maximum(V5AY,V6AY),V7AY)\n",
    "    axes.fill_between(Vmin.year.values, Vmin.values, Vmax.values, color=ccolors[3,:], alpha=0.2)\n",
    "\n",
    "    if Varname == 'TS':\n",
    "        axlabel = \"T$_S$\"\n",
    "    else:\n",
    "        axlabel = V1AY.long_name\n",
    "        \n",
    "    axes.legend(fontsize=8, framealpha=0.)\n",
    "    axes.set_xlabel('Year beyond 2020')\n",
    "    axes.set_ylabel(axlabel+' Change from 2020 IC ('+V1AY.units+')')\n",
    "    plt.savefig(fnprefix+'_'+Varname+'.pdf',format='pdf',dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    print('field processing complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b01879-fb5d-416d-9a28-f624d392ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import fsspec\n",
    "\n",
    "def s3load_zarr(s3path):\n",
    "    return xr.open_dataset(fsspec.get_mapper(s3path),engine = 'zarr')\n",
    "\n",
    "var = 'TS'\n",
    "experiment = \"20221014.v2.LR.WCYCLSSP245.E2_CNTL_01\"\n",
    "s3_path = f's3://mcb-zarr/E3SMv2/{experiment}/atm/proc/tseries/month_1/{experiment}.eam.h0.{var}.zarr'\n",
    "DS1 = s3load_zarr(s3_path)\n",
    "print('xxx',DS1)\n",
    "DS1f = center_time(DS1)\n",
    "DS1f.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e519159-b37b-416d-abdf-12d3695af66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS1f.time_bnds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fb9961-3669-49a4-a606-354ace0900d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35879ad5-1706-4d7d-9fc8-550e64ec9e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326fac8b-01a2-4a41-9b97-1d9044d0cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import fsspec\n",
    "\n",
    "def s3load_zarr(s3path):\n",
    "    return xr.open_dataset(fsspec.get_mapper(s3path),engine = 'zarr')\n",
    "\n",
    "experiment = 'b.e21.BSSP245smbb_MCBsse2.5Tg_R1.LE2-1031.002'\n",
    "var = 'TREFHT'\n",
    "s3_path = f's3://mcb-zarr/CESM2/{experiment}/atm/proc/tseries/month_1/{experiment}.cam.h0.{var}.zarr'\n",
    "\n",
    "print('s3_path',s3_path)\n",
    "\n",
    "## data is a lazy-loaded xarray dataset\n",
    "data = s3load_zarr(s3_path)\n",
    "time = data.time\n",
    "lat = data.lat\n",
    "print(data.TREFHT)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0b9717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_GA_tser(Varname, filespec, dirname, casename, extname):\n",
    "    ''' make global avg from tseries files\n",
    "        Varname: Variable name\n",
    "        filespec: the string used to format the filename for a model\n",
    "        dirname: directory where netcdf file is found\n",
    "        casename: name of case\n",
    "        extname: string used to specify years, etc\n",
    "        returns DataArray with timeseries of global averages\n",
    "    '''\n",
    "    ind1 = filespec.format(dir=dirname,case=casename,ext=extname,var=Varname)\n",
    "    print('opening',ind1)\n",
    "    file.write(ind1+'\\n')\n",
    "    DS1 = xr.open_mfdataset(ind1)\n",
    "    DS1 = center_time(DS1)\n",
    "    month_length = DS1.time.dt.days_in_month\n",
    "    twgts = month_length.groupby(\"time.year\") / month_length.groupby(\"time.year\").sum()\n",
    "    #print('twgts',twgts)\n",
    "    #print('xxx',DS1.time)\n",
    "    Var1 = xr_getvar(Varname,DS1)\n",
    "\n",
    "\n",
    "    if 'area' in DS1:\n",
    "        area = DS1['area']\n",
    "        print('area on DS1')\n",
    "    else: \n",
    "        if 'ncol' in DS1.dims:\n",
    "            print ('get CS data')\n",
    "            #areafile = '~/NetCDF_Files/F2010_PJR1.eam.h0.0001-01.nc'\n",
    "            areafile = '~/NetCDF_Files/ne30pg2.nc'\n",
    "            DSA = xr.open_mfdataset(areafile)\n",
    "            if len(DSA['ncol']) != len(DS1['ncol']):\n",
    "                raise ValueError('area file mismatch')\n",
    "            area = DSA.area\n",
    "        else:\n",
    "            print('calculating fv area weights')\n",
    "            lat = Var1['lat'].values\n",
    "            lon = Var1['lon'].values\n",
    "            aread = make_fvarea(lon,lat)\n",
    "            area = xr.DataArray(aread, dims=['lat','lon'], coords={'lon':lon,'lat':lat})\n",
    "            area.attrs['units']='steradians'\n",
    "        #print('area',area)\n",
    "        \n",
    "    wdims = area.dims\n",
    "    #print('wdims',wdims)\n",
    "    weights = area/(area.sum(dim=wdims))\n",
    "    #print('weights sum',weights.shape,weights.sum(dim=wdims).values)\n",
    "\n",
    "    #print(Varname, Var1)\n",
    "    # Global Avg by month\n",
    "    V1A = Var1.weighted(weights).mean(dim=wdims)\n",
    "    # calculate ann avgs accounting for number of days in month\n",
    "    V1AY = (V1A*month_length).groupby(\"time.year\").sum()/month_length.groupby(\"time.year\").sum()\n",
    "    #print('V1AY.values', V1AY.values)\n",
    "    return V1AY\n",
    "\n",
    "regtag = \"\"\n",
    "weights = None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e2a064-7305-42c9-8708-47d12893d890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_timex(DS1):\n",
    "    \"\"\"center_time(DS1)                                                                                                  \n",
    "                                                                                                                         \n",
    "    correct the time coordinate in DS1 to represent the center of the time bounds                                        \n",
    "                                                                                                                         \n",
    "    \"\"\"\n",
    "    DS = DS1.copy()\n",
    "    # the time coord is often registered at the end of the time averaging interval                                       \n",
    "    # reset to the midpoint of the interval                                                                              \n",
    "    time = DS['time'].copy()\n",
    "    #print('center_time time',time)\n",
    "    #print('xxx',time.values)                                                                                            \n",
    "    bndname = time.attrs['bounds']\n",
    "    #print('bndname',bndname)\n",
    "    # check whether bndname is present\n",
    "    #print('yyy',DS1)\n",
    "    if bndname not in DS1:\n",
    "        #print('need to improvise')\n",
    "        DS['time'] = DS.indexes['time'].shift(-1,\"MS\")\n",
    "        month_length = DS.time.dt.days_in_month.values\n",
    "        month_half = month_length/2\n",
    "        dm = month_half.astype(int)\n",
    "        hm = ((month_half - dm)*24.).astype(int)\n",
    "        DS['time'] = DS.indexes['time'].shift(dm,\"D\")\n",
    "        DS['time'] = DS.indexes['time'].shift(hm,\"h\")\n",
    "    else:\n",
    "        time_bnds = DS1[bndname]\n",
    "        #print('time_bnds',time_bnds)                                                                                        \n",
    "        tbdims = time_bnds.dims\n",
    "        #print('tbdims',tbdims)                                                                                              \n",
    "        tbd_name = ''\n",
    "        # find the bounds name (the dim that isn't time)                                                                     \n",
    "        for tbd in tbdims:\n",
    "            if tbd != 'time':\n",
    "                tbd_name = tbd\n",
    "        #print('tbd_name',tbd_name)                                                                                          \n",
    "        #print('tbdims',tbdims)                                                                                              \n",
    "        # if no bounds, then do nothing                                                                                      \n",
    "        if tbd_name != '':\n",
    "            #tb = time_bnds.values                                                                                           \n",
    "            #print('time_bnds',time_bnds)                                                                                    \n",
    "            tbm = time_bnds.mean(dim=tbd_name).values\n",
    "            #print('yyy',tbm)\n",
    "            #1./0.\n",
    "            DS.coords[\"time\"] = tbm\n",
    "            DS['time'].attrs['long_name'] = 'time'\n",
    "            DS['time'].attrs['bounds'] = 'time_bnds'\n",
    "    time = DS['time'].values\n",
    "    print('center_time returning DS', time[0],time[1],time[-2],time[-1])\n",
    "    return DS\n",
    "\n",
    "def make_GA_ts2(Varname, s3_path ):\n",
    "    ''' make global avg from tseries files\n",
    "        Varname: Variable name\n",
    "        filespec: the string used to format the filename for a model\n",
    "        dirname: directory where netcdf file is found\n",
    "        casename: name of case\n",
    "        extname: string used to specify years, etc\n",
    "        returns DataArray with timeseries of global averages\n",
    "    '''\n",
    "    #print('xx s3_path',s3_path)\n",
    "    DS1 = s3load_zarr(s3_path)\n",
    "    #print('xxx DS1',DS1)\n",
    "    #DS1 = xr.open_mfdataset(ind1)\n",
    "    DS1 = center_timex(DS1)\n",
    "    month_length = DS1.time.dt.days_in_month\n",
    "    twgts = month_length.groupby(\"time.year\") / month_length.groupby(\"time.year\").sum()\n",
    "    #print('twgts',twgts)\n",
    "    #print('xxx',DS1.time)\n",
    "    Var1 = xr_getvar(Varname,DS1)\n",
    "    area = DS1['area']\n",
    "    #print('Var1',Var1)\n",
    "    #1./0.    \n",
    "    wdims = area.dims\n",
    "    #print('wdims',wdims)\n",
    "    weights = area/(area.sum(dim=wdims))\n",
    "    #print('weights sum',weights.shape,weights.sum(dim=wdims).values)\n",
    "\n",
    "    #print(Varname, Var1)\n",
    "    # Global Avg by month\n",
    "    V1A = Var1.weighted(weights).mean(dim=wdims)\n",
    "    # calculate ann avgs accounting for number of days in month\n",
    "    V1AY = (V1A*month_length).groupby(\"time.year\").sum()/month_length.groupby(\"time.year\").sum()\n",
    "    #print('V1AY.values', V1AY.values)\n",
    "    return V1AY"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "pjrpy3",
   "language": "python",
   "name": "pjrpy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
